# -*- coding: utf-8 -*-
"""submission-2_time-series.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L0c9TfjKcyIMaVeeHw7Fqf9qqYODOB8c
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split

df = pd.read_csv('testset.csv')

df.tail()

df.isnull().sum()

df = df[["datetime_utc"," _tempm"]]

df.columns =["date", 'temp']

df.isnull().sum()

df.dropna(inplace = True)

df["date"] = pd.to_datetime(df["date"])

df = df.set_index('date')

temp_max = df['temp'].max()
temp_min = df['temp'].min()

scaler = MinMaxScaler(feature_range = (0, 1))
data = scaler.fit_transform(df)
temp_max_normalized = scaler.transform([[temp_max]])[0][0]
temp_min_normalized = scaler.transform([[temp_min]])[0][0]

plt.plot(data)

train_data, val_data = train_test_split(data, test_size=0.2, shuffle=False)

def dataset(dataset, time_step=1):
    X, Y = [], []
    for i in range(len(dataset)-time_step-1):
        a = dataset[i:(i+time_step), 0]
        X.append(a)
        Y.append(dataset[i + time_step, 0])
    return np.array(X), np.array(Y)

X_train, y_train = dataset(train_data, 100)
X_val, y_val = dataset(val_data, 100)

X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)

model = tf.keras.Sequential([
    tf.keras.layers.LSTM(64, return_sequences=True, input_shape=(100, 1)),
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.LSTM(64, return_sequences=True),
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.Dense(8, activation='relu'),
    tf.keras.layers.Dense(1)
])

early_stop = EarlyStopping(
    monitor='loss',
    min_delta=0,
    patience=2,
    verbose=1,
    mode='auto'
)

optimizer = tf.keras.optimizers.SGD(learning_rate=1.0000e-04, momentum=0.9)

model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"]
)

history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=10,
    batch_size=128,
    callbacks=[early_stop],
    verbose=1
)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.legend(['train', 'test'], loc = 'upper right')
plt.show()

plt.plot(history.history['mae'])
plt.plot(history.history['val_mae'])
plt.title('Model Mae')
plt.ylabel('Mae')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='lower right')
plt.show()

threshold_mae = (temp_max_normalized - temp_min_normalized) * 10 / 100
print(f'Threshold MAE: {threshold_mae:.4f}')

val_predictions = model.predict(X_val)
val_mae = np.mean(np.abs(val_predictions - y_val))

if val_mae < threshold_mae:
    print(f'MAE: {val_mae:.4f} < Threshold MAE: {threshold_mae:.4f}.')
else:
    print(f'MAE: {val_mae:.4f} > Threshold MAE: {threshold_mae:.4f}.')

